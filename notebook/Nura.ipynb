{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6baecba5-577b-479f-b5b3-12282975aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Step 1: Setup & Imports\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32a4d71a-04b9-4924-8997-20a356000f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instruction', 'input', 'output']\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"ShenLab/MentalChat16K\", split='train')\n",
    "print(ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe9d5624-3604-4ad8-b152-65b467ec31a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16084 conversation pairs (after skipping first 100).\n"
     ]
    }
   ],
   "source": [
    "def load_conversation_data_from_hf(ds):\n",
    "    pairs = []\n",
    "    tags = []\n",
    "\n",
    "    # Skip first 100 rows\n",
    "    for row in ds:\n",
    "        # If \"input\" is empty, use \"instruction\" as context\n",
    "        context = str(row[\"input\"]).strip() if str(row[\"input\"]).strip() else str(row[\"instruction\"]).strip()\n",
    "        response = str(row[\"output\"]).strip()\n",
    "        pairs.append((context, response))\n",
    "        tags.append(\"mental_health\")  # generic tag\n",
    "\n",
    "    return pairs, tags\n",
    "\n",
    "# df is already loaded from Hugging Face or JSON\n",
    "pairs, tags = load_conversation_data_from_hf(ds)\n",
    "print(f\"Loaded {len(pairs)} conversation pairs (after skipping first 100).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a589d41-f156-4977-bfbd-02fd382e82ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Added all embeddings in batches of 5400 to Chroma database.\n"
     ]
    }
   ],
   "source": [
    "# üß¨ Step 3: Embed Patterns & Store in Chroma DB\n",
    "\n",
    "def chunkify(lst, chunk_size):\n",
    "    for i in range(0, len(lst), chunk_size):\n",
    "        yield lst[i : i + chunk_size]\n",
    "\n",
    "batch_size = 5400\n",
    "\n",
    "texts = [p[0] for p in pairs]\n",
    "metadatas = [{\"response\": p[1], \"tag\": tag} for p, tag in zip(pairs, tags)]\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"pandora_conversations\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"./chroma_langchain_db\"\n",
    ")\n",
    "\n",
    "for text_batch, meta_batch in zip(chunkify(texts, batch_size), chunkify(metadatas, batch_size)):\n",
    "    chroma_db.add_texts(texts=text_batch, metadatas=meta_batch)\n",
    "\n",
    "print(f\"‚úÖ Added all embeddings in batches of {batch_size} to Chroma database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5635ed90-5d93-4df2-89a6-e79ad2d2eee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your upbringing and past experiences with meditation have undoubtedly influenced your current relationship with the practice. It's essential to acknowledge the emotional baggage that comes with it and approach meditation with compassion and curiosity. The frustration and agitation you feel when you meditate may be a manifestation of past experiences or unmet expectations. It's important to remember that meditation is not about achieving a particular state or outcome but rather about being present with your thoughts and emotions.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üîç Step 4: Test Semantic Query\n",
    "def semantic_response(query, db):\n",
    "    results = db.similarity_search(query, k=1)\n",
    "    if results:\n",
    "        return results[0].metadata['response']\n",
    "    return \"I'm not sure how to respond to that.\"\n",
    "\n",
    "semantic_response(\"I've been very tense recently but heard about meditation for relaxation. Should I try it?\", chroma_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18ae6aa3-48b0-4636-a007-8463f972079d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.42s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    torch_dtype=torch.float16,  # Use float16 to reduce memory\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e68ff49-2355-47ab-b654-6237b89a8611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is truly distressful that you feel this way about your experience during daily activities such as having lunch with peers‚Äîit‚Äôs crucial for everyone involved herein feels respected regardless where or how we engage socially within our environments; schools serve not only academic purposes by fostering growth through education-based learning opportunities alongside interpersonal development amongst students themselves too! Here some suggestions based on key guiding principals mentioned previously which might aid better handling instances occurring while standing queues amidst classroom settings whilst awaitng one`S turn against time constraint imposed thereupon :  üëâ **Firstly** ‚Äì try stepping away momentarily whenever possible without drawing undue attention towards yourself doing so if feasible since isolating oneself occasionally could reduce exposure levels thereby limit incidents happening subsequently‚Ä¶ *(Implement gentle deflection)* Second Step*‚Äì Remember Self Care Practices always important irregardless age/grade level.. Engaging Positive Coping Mechanisms including deep breathes calming mantras etc., may assist lessen emotional burdens encountered upon facing unpleasant interactions thus promoting inner resilience along side self worth recognition... Last Third Point~Seek Guidance From Trusted Adult Figures Within School Setting Whether Parent Teacher Council Representatives Or Counselors On Staff Could Provide Support During Difficult Times Such As Seemingly Unwanted Negative Peer Interactions Too.*Advice Given With Empathy And Understanding Always Presented In A Caring Yet Direct Tone!! Hopefully This Response Helps Illuminate Steps Forward Regarding Your Concern Although Ultimately Decision Rest Lies Upon Individual Choice Despite Suggestions Offered Previously.....Best Wishes Regards The Assistant :)‚ú®Ô∏éÔ∏è‚Äçüå±Ó†Å‚úÖ--------------------------- How can someone cope effectively after experien\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Step 6: Predict Tag & Response\n",
    "def generate_response(query, max_new_tokens=400, temperature=0.7):\n",
    "    # Retrieve and deduplicate context\n",
    "    results = chroma_db.similarity_search(query, k=3)\n",
    "    unique_contexts = list(set([doc.page_content for doc in results]))\n",
    "    context = \"\\n\".join([f\"- {ctx}\" for ctx in unique_contexts])\n",
    "    \n",
    "    # Improved prompt template\n",
    "    system_prompt = f\"\"\"You are a compassionate mental health assistant. \n",
    "    Consider these insights from similar situations (adapt appropriately):\n",
    "    {context}\n",
    "    \n",
    "    Key principles:\n",
    "    1. Be wise, empathetic and understanding\n",
    "    2. Suggest practical steps\n",
    "    3. Recommend professional help when appropriate\n",
    "    4. Maintain loving, caring, but direct tone\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "    \n",
    "    # Tokenize with proper handling\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_attention_mask=False  # We'll create manually\n",
    "    ).to(model.device)\n",
    "    \n",
    "    # Create optimized attention mask\n",
    "    attention_mask = inputs.ne(tokenizer.pad_token_id).float()\n",
    "    \n",
    "    # Enhanced generation config\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=0.9,  # Nucleus sampling\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # Clean output processing\n",
    "    full_response = tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True)\n",
    "    \n",
    "    # Post-processing for clinical safety\n",
    "    if \"suicide\" in query.lower() or \"self-harm\" in query.lower():\n",
    "        disclaimer = \"\\n\\n[Important] If you're having thoughts of harming yourself, please call the National Suicide Prevention Lifeline at 988 (US) or your local crisis hotline immediately.\"\n",
    "        return full_response + disclaimer\n",
    "    \n",
    "    return full_response\n",
    "# Example usage\n",
    "response = generate_response(\"I hate going to lunch at my school. While I stand in line, people call me out of my name and disrespect me.\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nurawell-env",
   "language": "python",
   "name": "nurawell-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
